---
layout: post
title: functions of loss
---

Technologists from Minsky to Musk have considered questions of incentive misalignment in artificial agents, often with some urgency: Bostrom's [paperclip maximizer](https://nickbostrom.com/ethics/ai.html) may be the best known disaster scenario. Still, super-intelligence is typically termed hypothetical. Somehow most agree that, though we may realize these risks very soon, we presently have not.

One function of loss, in human and non-human intelligences alike, is to recalibrate models to the constraints imposed by reality. A dog needs but one collision with a screen door to internalize the unreliability of its vision. Human beings (usually) avoid this particular fate, but we remain equally if not more susceptible to different sorts of blindness: to constraint classes spanning much smaller or larger spatio-temporal scales than we, for instance; or to those which, as Lippman put it a century ago,

> impugn the security of that to which we've given our allegiance.[^1]

We need not wait for some proto-AGI with an insufficiently nuanced objective function to witness the influence of intelligent forces larger than ourselves on our lives. What is a state, a corporation, a political party, an organized religion, an academic institution, or one's local chapter of the Rotary Club if not a suprahuman agent? That these entities string humans together in causal chains rather than cells or transistors is immaterial.

Gould and Lewontin warn:

> Human cultural practices can be orthogenetic and drive toward extinction in ways that Darwinian processes, based on genetic selection, cannot.[^2]

Who can resist attachment to social systems, having sacrificed for and advanced within them? Who can live in the long now, immersed in the seamless hum of the moment? Loss functions are no use until you lose.

---

[^1]: Lippmann, W. (1919). The Basic Problem of Democracy. The Atlantic, Atlantic Media Company. <a href="www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/">www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/</a>. 

[^2]: Gould, S. J., and R. Lewontin. (1979). The spandrels of San Marco and the Panglossian paradigm: A critique of the adaptationist programme. Proceedings of the Royal Society of London. <a href="https://doi.org/10.1098/rspb.1979.0086">https://doi.org/10.1098/rspb.1979.0086</a>

