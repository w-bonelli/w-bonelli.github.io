---
layout: post
title: loss functions
---

Technologists from Minsky to Musk have considered questions of incentive misalignment in artificial agents, often with urgency: Bostrom's [paperclip maximizer](https://nickbostrom.com/ethics/ai.html) is one of the better known framings. Still, super-intelligence is termed hypothetical. Somehow most agree that, though we may realize these risks "soon" (how soon varies, depending who is asked), we have not yet breached the proverbial seal.

One function of loss, among humans and non-humans alike, is to recalibrate models to the constraints imposed by reality. A cat or dog needs one collision with a screen door to internalize the unreliability of its vision. Though we tend to avoid this particular fate, different classes of objects present us with equal difficulty: for instance, as Lippman put it a century ago, those which

> impugn the security of that to which we've given our allegiance.[^1]

We are told, claims Deleuze, that governments and

> corporations have a soul, which is the most terrifying news in the world.[^2]

They also have bodies. We need not wait for a badly nuanced objective function to snap its shackles to witness alien intelligence. What are the NSA, the Executive Office of the President of the United States, or the Centers for Disease Control and Prevention if not suprahuman agents? That these things string people together in causal chains rather than cells or transistors is immaterial.

What do they maximize? It seems we live in a surveillance state incapable of controlling a pandemic, and the planet grows less hospitable by the year. Gould and Lewontin warn:

> Human cultural practices can be orthogenetic and drive toward extinction[^3].

Having sacrificed for and advanced within some milieu, who can resist attachment to it? Who can live in the long now, immersed in the seamless hum of the moment? Loss functions are no use until you lose.

---

[^1]: Lippmann, W. (1919). The Basic Problem of Democracy. The Atlantic, Atlantic Media Company. <a href="www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/">www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/</a>. 

[^2]: Deleuze, G. (1992). Postscript on the Societies of Control.

[^3]: Gould, S. J., and R. Lewontin. (1979). The spandrels of San Marco and the Panglossian paradigm: A critique of the adaptationist programme. Proceedings of the Royal Society of London. <a href="https://doi.org/10.1098/rspb.1979.0086">https://doi.org/10.1098/rspb.1979.0086</a>

