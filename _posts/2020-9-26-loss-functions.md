---
layout: post
title: loss functions
---

> If the earth must lose that great portion of its pleasantness which it owes to things that the unlimited increase of wealth and population would extirpate from it, for the mere purpose of enabling it to support a larger, but not a better or a happier population, I sincerely hope, for the sake of posterity, that they will be content to be stationary, long before necessity compel them to it.[^1]

Technologists from Minsky to Musk have considered questions of incentive misalignment in artificial agents, often with urgency: Bostrom's [paperclip maximizer](https://nickbostrom.com/ethics/ai.html) is one of the better known framings. Still, super-intelligence is termed hypothetical. Somehow most agree that, though we may realize these risks "soon" (how soon varies, depending who is asked), we have not yet breached the proverbial seal.

One function of loss, among humans and non-humans alike, is to recalibrate models to the constraints imposed by reality. A cat or dog needs one collision with a screen door to learn not to trust its vision. We tend to avoid this particular fate, but we are equally blind to (and far less likely to internalize the dangers of) different classes of objects: for instance, as Lippman put it a century ago, those which

> impugn the security of that to which we've given our allegiance.[^2]

We are told, claims Deleuze, that institutions, governments, and

> corporations have a soul, which is the most terrifying news in the world.[^3]

They have minds and bodies too. We need not wait for a badly nuanced objective function to snap its shackles to witness alien intelligence. What are Google, the NSA, Facebook, the Pentagon, ExxonMobil, Twitter, the Executive Office of the President of the United States, the WHO, or the Centers for Disease Control and Prevention if not suprahuman agents? That these things string people together in causal chains rather than cells or transistors is immaterial.

What do they maximize? It seems we live in a surveillance state incapable of controlling a pandemic, and the planet grows less hospitable by the year. Gould and Lewontin warn:

> Human cultural practices can be orthogenetic and drive toward extinction[^4].

Having sacrificed for and advanced within some milieu, who can resist attachment to it? Who can live in the long now, immersed in the seamless hum of the moment? Loss functions are no use until you lose.

---

[^1]: Mill, J. S. (1848). Principles of Political Economy.

[^2]: Lippmann, W. (1919). The Basic Problem of Democracy. The Atlantic, Atlantic Media Company. <a href="https://www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/">https://www.theatlantic.com/magazine/archive/1919/11/the-basic-problem-of-democracy/569095/</a>. 

[^3]: Deleuze, G. (1992). Postscript on the Societies of Control.

[^4]: Gould, S. J., and R. Lewontin. (1979). The spandrels of San Marco and the Panglossian paradigm: A critique of the adaptationist programme. Proceedings of the Royal Society of London. <a href="https://doi.org/10.1098/rspb.1979.0086">https://doi.org/10.1098/rspb.1979.0086</a>

